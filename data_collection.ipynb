{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonin/miniconda3/envs/tfm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Load Dataset\n",
    "- Simple dataset for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dataset = load_dataset(\"javalove93/sentiment-analysis-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = sentiment_dataset['train']['text'][0]\n",
    "\n",
    "# Split by both '.' and '!'\n",
    "sentences = re.split(r'[.!]', text)\n",
    "sentences[:-1]\n",
    "\n",
    "sentiment_dataset['train']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matching label strategy**\n",
    "- Split each sequence into single sentence.\n",
    "- Regrouping sentences with same label to create pairs : focus on relationship between them (even if not in the original dataset) !\n",
    "- Here 2 sentiments : positive or negative\n",
    "- Pairs should be list of tuples or list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I love this movie!', \" It's amazing.\"),\n",
       " (\" It's amazing.\", 'What a great experience!'),\n",
       " ('What a great experience!', ' Highly recommended.'),\n",
       " (' Highly recommended.', \"This is the best book I've ever read.\"),\n",
       " (\"This is the best book I've ever read.\", \"I'm so happy with my purchase!\"),\n",
       " (\"I'm so happy with my purchase!\", 'I had a fantastic time!'),\n",
       " ('I had a fantastic time!', 'Absolutely loved it!'),\n",
       " ('Absolutely loved it!', 'This is incredible!'),\n",
       " ('This is incredible!', \"I'm very impressed with the performance.\"),\n",
       " (\"I'm very impressed with the performance.\", \"I can't wait to try it again!\"),\n",
       " (\"I can't wait to try it again!\", 'Excellent service and friendly staff.'),\n",
       " ('Excellent service and friendly staff.',\n",
       "  'Highly satisfied with the results.'),\n",
       " ('Highly satisfied with the results.', 'This is a must-see!'),\n",
       " ('This is a must-see!', 'It was a wonderful evening.'),\n",
       " ('It was a wonderful evening.', 'I highly recommend this service.'),\n",
       " ('I highly recommend this service.', 'Great value for money!'),\n",
       " ('Great value for money!', \"I'm so glad I bought this!\"),\n",
       " (\"I'm so glad I bought this!\", 'This is a fantastic product!'),\n",
       " ('This is a fantastic product!', \"I'm very happy with this service.\"),\n",
       " (\"I'm very happy with this service.\",\n",
       "  'I would definitely recommend this to others.'),\n",
       " ('I would definitely recommend this to others.', 'I had a great experience.'),\n",
       " ('I had a great experience.', 'This is a great place to visit.'),\n",
       " ('This is a great place to visit.', 'I love this!'),\n",
       " ('I love this!', 'This is amazing!'),\n",
       " ('This is amazing!', \"I'm so happy!\"),\n",
       " (\"I'm so happy!\", 'This is so good!'),\n",
       " ('This is so good!', \"I'm impressed!\"),\n",
       " (\"I'm impressed!\", 'This is perfect!'),\n",
       " ('This is perfect!', \"I'm thrilled!\"),\n",
       " (\"I'm thrilled!\", 'This is excellent!'),\n",
       " ('This is excellent!', \"I'm delighted!\"),\n",
       " ('This restaurant is terrible.', ' The food was cold.'),\n",
       " (' The food was cold.', 'The product arrived damaged.'),\n",
       " ('The product arrived damaged.', \" I'm very disappointed.\"),\n",
       " (\" I'm very disappointed.\", 'The service was slow and the staff were rude.'),\n",
       " ('The service was slow and the staff were rude.',\n",
       "  'This is a complete waste of money.'),\n",
       " ('This is a complete waste of money.',\n",
       "  'The quality is poor and it broke after a week.'),\n",
       " ('The quality is poor and it broke after a week.',\n",
       "  'I would not recommend this to anyone.'),\n",
       " ('I would not recommend this to anyone.',\n",
       "  'The instructions were unclear and confusing.'),\n",
       " ('The instructions were unclear and confusing.',\n",
       "  \"This is by far the worst experience I've had.\"),\n",
       " (\"This is by far the worst experience I've had.\",\n",
       "  'The product did not meet my expectations.'),\n",
       " ('The product did not meet my expectations.',\n",
       "  \"I'm extremely disappointed with the quality.\"),\n",
       " (\"I'm extremely disappointed with the quality.\",\n",
       "  'I regret buying this product.'),\n",
       " ('I regret buying this product.', 'The food was bland and tasteless.'),\n",
       " ('The food was bland and tasteless.',\n",
       "  'The delivery was late and the item was damaged.'),\n",
       " ('The delivery was late and the item was damaged.',\n",
       "  'The customer service was terrible.'),\n",
       " ('The customer service was terrible.', \"I'm not satisfied with the product.\"),\n",
       " (\"I'm not satisfied with the product.\",\n",
       "  \"This is the worst movie I've ever seen.\"),\n",
       " (\"This is the worst movie I've ever seen.\", 'I hate this!'),\n",
       " ('I hate this!', 'This is terrible!'),\n",
       " ('This is terrible!', \"I'm so sad.\"),\n",
       " (\"I'm so sad.\", 'This is so bad!'),\n",
       " ('This is so bad!', \"I'm disappointed.\"),\n",
       " (\"I'm disappointed.\", 'This is awful!'),\n",
       " ('This is awful!', \"I'm frustrated.\"),\n",
       " (\"I'm frustrated.\", 'This is unacceptable.'),\n",
       " ('This is unacceptable.', \"I'm angry.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple # for cool decorations of functions\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Splitting initial sequences\n",
    "def create_sequences(dataset: datasets.Dataset) -> List[Tuple[str, str]]:\n",
    "    sequences = dataset['train']\n",
    "    seq_pos = []\n",
    "    seq_neg = []\n",
    "    for sequence,label in zip(sequences['text'],sequences['label']):\n",
    "        sentences = re.split(r'([.!])',sequence)\n",
    "        sentences = [sentences[i] + sentences[i+1] for i in range(0, len(sentences)-1,2)]\n",
    "        if len(sentences[-1]) == 0:\n",
    "            sentences = [s[:MAX_LEN] for s in sentences[:-1]] # remove last sep empty\n",
    "        if label == 'positive':\n",
    "            seq_pos += sentences\n",
    "        else:\n",
    "            seq_neg += sentences\n",
    "    return seq_pos, seq_neg\n",
    "\n",
    "seq_pos, seq_neg = create_sequences(sentiment_dataset)\n",
    "\n",
    "# Generating pairs\n",
    "def generate_pairs(sequences: list) -> list:\n",
    "    return [(s1,s2) for s1,s2 in zip(sequences[:-1],sequences[1:])]\n",
    "\n",
    "pairs_pos = generate_pairs(seq_pos)\n",
    "pairs_neg = generate_pairs(seq_neg)\n",
    "\n",
    "sentences = seq_pos + seq_neg\n",
    "pairs = pairs_pos + pairs_neg\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Tokenization\n",
    "- Using WordPiece tokenizer to produce BERT inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 109935.11it/s]\n",
      "/home/antonin/miniconda3/envs/tfm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1924: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 16, 44, 43, 43, 48, 14, 88, 101, 47, 35, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizer\n",
    "# Creating batches\n",
    "batch_size = 30\n",
    "\n",
    "\n",
    "def create_batches(batch_size : int,sentences : list):\n",
    "    text_data = []\n",
    "    file_count = 0\n",
    "    for word in tqdm.tqdm(sentences):\n",
    "\n",
    "        text_data.append(word)\n",
    "\n",
    "        if len(text_data) == batch_size:\n",
    "            with open(f'./data/text_{file_count}.txt', 'w', encoding='utf-8') as file:\n",
    "                file.write('\\n'.join(text_data))\n",
    "            text_data = []\n",
    "            file_count += 1\n",
    "\n",
    "    with open(f'./data/text_{file_count}.txt', 'w', encoding='utf-8') as file:\n",
    "                file.write('\\n'.join(text_data))\n",
    "\n",
    "create_batches(batch_size,sentences)\n",
    "\n",
    "paths = [str(x) for x in Path('./data').glob('**/*.txt')]\n",
    "\n",
    "# Training the tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train( \n",
    "    files=paths,\n",
    "    vocab_size=30_000, \n",
    "    min_frequency=5,\n",
    "    limit_alphabet=1000, \n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )\n",
    "\n",
    "# os.mkdir('./bert-it-1')\n",
    "tokenizer.save_model('./bert-it-1', 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)\n",
    "\n",
    "enc = tokenizer.encode(\"Hello friends\")\n",
    "# tokenizer.decode(enc)\n",
    "enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Sequence Embedding\n",
    "- Transform sequences to account for uniform representation as inputs for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__ (self, tokenizer, data_pair: List[Tuple[str, str]], max_len: int):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lines = data_pair\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self,index: int) -> dict:\n",
    "        t1, t2, is_next_label = self.get_seq(index)\n",
    "\n",
    "        t1_token_ids = self.tokenizer(t1)['input_ids'][1:-1] # remove CLS and SEP\n",
    "        t2_token_ids = self.tokenizer(t2)['input_ids'][1:-1]\n",
    "\n",
    "        t1_random, t1_label = self.random_word(t1_token_ids)\n",
    "        t2_random, t2_label = self.random_word(t2_token_ids)\n",
    "\n",
    "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
    "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
    "\n",
    "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.max_len]\n",
    "        bert_input = (t1 + t2)[:self.max_len]\n",
    "        bert_label = (t1_label + t2_label)[:self.max_len]\n",
    "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.max_len - len(bert_input))]\n",
    "        bert_input += padding\n",
    "        bert_label += padding\n",
    "        segment_label += padding\n",
    "\n",
    "        return {\"bert_input\": torch.tensor(bert_input),\n",
    "                  \"bert_label\": torch.tensor(bert_label),\n",
    "                  \"segment_label\": torch.tensor(segment_label),\n",
    "                  \"is_next\": torch.tensor(is_next_label)}\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.lines)\n",
    "\n",
    "    def random_word(self,token_ids: list) -> Tuple[list, list]:\n",
    "        n_tokens = len(token_ids)\n",
    "        output_label_id = [0] * n_tokens # real output for masked info\n",
    "        output_token_id = token_ids # masked output\n",
    "\n",
    "        for i,token_id in enumerate(token_ids):\n",
    "            p = random.random()\n",
    "\n",
    "            if p <= 0.15:\n",
    "                p = random.random()\n",
    "\n",
    "                if p <= 0.8:\n",
    "                    output_token_id[i] = self.tokenizer.vocab['[MASK]']\n",
    "                \n",
    "                elif p <= 0.9:\n",
    "                    output_token_id[i] = random.randrange(len(self.tokenizer.vocab))\n",
    "                else:\n",
    "                    output_token_id[i] = token_id\n",
    "                \n",
    "                output_label_id[i] = token_id\n",
    "        \n",
    "        return output_token_id, output_label_id\n",
    "\n",
    "\n",
    "    def get_seq(self, index):\n",
    "        \"\"\"\n",
    "            Returns a sentence pair (str) with index is_next\n",
    "        \"\"\"\n",
    "        t1,t2 = self.get_corpus_line(index)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "        \n",
    "    def get_corpus_line(self, index):\n",
    "        return self.lines[index]\n",
    "        \n",
    "    def get_random_line(self):\n",
    "        return self.lines[random.randrange(len(self.lines))][1]\n",
    "    \n",
    "train_data = BERTDataset(tokenizer,pairs,MAX_LEN)\n",
    "# train_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Embeddings\n",
    "- Token Embeddings : projection to vector space of each token\n",
    "- Positional Embeddings : Keeps track of position of words within sequences, essential to get context about sentence structure\n",
    "- Segment Embeddings : label precising which part of the sequence a word belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def positional_encoding(L: int, d_model: int, N: int = 10000) -> np.array:\n",
    "    pos = np.arange(L)[:, np.newaxis] # [L,1]\n",
    "    i = np.arange(d_model)[np.newaxis, :] # [1,d_model]\n",
    "\n",
    "    angle_rates = 1 / np.power(N, (2*(i//2)) / d_model)\n",
    "    angle_rads = pos * angle_rates # [L,d_model]\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    return angle_rads\n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=64):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.requires_grad = False\n",
    "\n",
    "        pe += positional_encoding(max_len, d_model)\n",
    "\n",
    "        self.pe = pe.unsqueeze(0) # extra batch dimension : [1, 64, 128]\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.pe\n",
    "    \n",
    "\n",
    "class BERTEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_size: int, max_len: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0) # padding, seqA, seqB\n",
    "        self.position = PositionalEmbedding(embed_size,max_len)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, seq: list, segment_label: list):\n",
    "        embs = self.token(seq) + self.position() + self.segment(segment_label)\n",
    "        return self.dropout(embs)\n",
    "\n",
    "# Test PE\n",
    "# d_model = 128\n",
    "# pos_encoder = PositionalEmbedding(d_model,MAX_LEN)\n",
    "# pos_encoder.forward().shape == torch.Size([1,64,128])\n",
    "\n",
    "# Test Embeddings\n",
    "d_model = 32\n",
    "seq = train_data[3][\"bert_input\"]\n",
    "segment_label = train_data[3][\"segment_label\"]\n",
    "bert_emb = BERTEmbedding(vocab_size=len(tokenizer.vocab),embed_size=d_model, max_len=MAX_LEN, dropout=0.1)\n",
    "inputs = bert_emb.forward(seq=seq, segment_label=segment_label)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Encoder Architecture\n",
    "\n",
    "* Single Head Attention\n",
    "$$\\underbrace{\\vec{E}}_{n*d_{model}}\\underbrace{Q}_{d_{model}*d_k} \\rightarrow \\underbrace{Q_{\\vec{E}}}_{n*d_k}$$\n",
    "$$(QK^T)_{i,j} = Q_{\\vec{E}}[i]Q_{\\vec{K}}^T[j]$$\n",
    "\n",
    "* Need to **mask** scores when j > i : prevent future tokens to give info to the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleHeadAttention(torch.nn.Module):\n",
    "    def __init__(self,d_model: int,d_k: int,dropout_rate=0.1):\n",
    "        super(SingleHeadAttention, self).__init__()\n",
    "\n",
    "        self.query = torch.nn.Linear(d_model,d_k)\n",
    "        self.key = torch.nn.Linear(d_model, d_k)\n",
    "        self.values = torch.nn.Linear(d_model, d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        ## TODO : improve self.vals with low-rank strat\n",
    "\n",
    "    def forward(self, E: torch.Tensor, masked: bool= False) -> torch.Tensor:\n",
    "        Q_emb = self.query(E)\n",
    "        K_emb = self.key(E)\n",
    "        V_emb = self.values(E)\n",
    "\n",
    "        dk = self.query.size(-1)\n",
    "        scores = torch.matmul(Q_emb, K_emb.transpose()) / torch.sqrt(dk)\n",
    "        if masked: # no masking in the case of the encoder part\n",
    "            mask = torch.triu(torch.ones_like(scores),diagonal=1).bool()\n",
    "            scores = scores.masked_fill_(mask,-1e12) # use very low values to mask scores and prevent future words to influence\n",
    "        \n",
    "        attention_scores = F.softmax(scores, dim=-1) # softmax normalization on rows of QK^T\n",
    "        attention_scores = self.dropout(attention_scores)\n",
    "\n",
    "        attention_values = torch.matmul(attention_scores,V_emb)\n",
    "        return attention_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.2119, 0.2119, 0.5761]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape\n",
    "d_model = inputs.shape[2]\n",
    "d_k = 16\n",
    "\n",
    "inputs = inputs.float()\n",
    "linear = torch.nn.Linear(d_model, d_k)\n",
    "output = linear(inputs[0])\n",
    "output.shape\n",
    "\n",
    "M1 = torch.randn(size=(2,3))\n",
    "M2 = torch.randn(size=(4,3))\n",
    "\n",
    "M = torch.matmul(M1,M2.transpose(-2,-1))\n",
    "M.shape\n",
    "\n",
    "M = torch.Tensor(np.array([[1,2,3],[5,5,6]]))\n",
    "F.softmax(M,dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
