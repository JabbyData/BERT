{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordPiece guideline\n",
    "\n",
    "* Init vocab :\n",
    "    * Characters at the beginning of each word\n",
    "    * Characters in each word preceded by the prefix '##'\n",
    "    * Special tokens\n",
    "    * Compute pairs in each word with their respective frequency\n",
    "\n",
    "* Objects : \n",
    "    * Vocab : list containing the vocab\n",
    "    * Splits : dictionary containing pairs (updated) with their frequency in each word\n",
    "\n",
    "* Iteration : \n",
    "    * Merge pairs with the highest score (arbitrary choice equality)\n",
    "    * Until size_vocab reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"This is the Hugging Face Course.\",\n",
    "    \"This chapter is about tokenization.\",\n",
    "    \"This section shows several tokenizer algorithms.\",\n",
    "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Review\n",
    "**Defaultdict** : Python dictionnary which values can be initialized even if key not already present <br>\n",
    "**set.update** : Insert multiple items at once in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "def init_vocab(text: List[str]) -> Tuple[list, list, list]:\n",
    "    special_tokens = ['[CLS]','[SEP]','[PAD]','[UNK]','[MASK]']\n",
    "    vocab = set()\n",
    "    word_freq = dd(int)\n",
    "    splits = dd(list)\n",
    "\n",
    "    for sentence in text:\n",
    "        words = sentence.split(\" \")\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "            if word not in splits:\n",
    "                splits[word] = [word[0]] + [f\"##{c}\" for c in word[1:]]\n",
    "                vocab.update(splits[word])\n",
    "\n",
    "    return special_tokens + list(vocab), word_freq, splits\n",
    "\n",
    "# time complexity : O(nb of letters in the text)\n",
    "\n",
    "vocab, word_freq, splits = init_vocab(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Review\n",
    "\n",
    "* sorted() : **key** param enables to filter sort\n",
    "* list of (key,value) using **list(dict.items())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict # for typing purposes\n",
    "\n",
    "def compute_init_scores(splits: defaultdict, word_freq: defaultdict) -> Tuple[list,defaultdict]:\n",
    "    scores = dd(int)\n",
    "    pair_freq = dd(int)\n",
    "    indiv_freq = dd(int)\n",
    "    for word, token_list in splits.items():\n",
    "        for i in range(1,len(token_list)):\n",
    "            pair = (token_list[i-1] , token_list[i])\n",
    "            indiv_freq[token_list[i-1]] += word_freq[word]\n",
    "            pair_freq[pair] += word_freq[word]\n",
    "        indiv_freq[token_list[-1]] += word_freq[word]\n",
    "    \n",
    "    for pair,freq in pair_freq.items():\n",
    "        scores[pair] = freq / (indiv_freq[pair[0]] * indiv_freq[pair[1]])\n",
    "    \n",
    "\n",
    "    return sorted(list(scores.items()),key=lambda item: item[1]), indiv_freq\n",
    "\n",
    "def compute_scores(splits: defaultdict, word_freq: defaultdict, indiv_freq: defaultdict) -> list:\n",
    "    scores = dd(int)\n",
    "    pair_freq = dd(int)\n",
    "    for word, token_list in splits.items():\n",
    "        for i in range(1,len(token_list)):\n",
    "            pair = (token_list[i-1] , token_list[i])\n",
    "            pair_freq[pair] += word_freq[word]\n",
    "    \n",
    "    for pair,freq in pair_freq.items():\n",
    "        scores[pair] = freq / (indiv_freq[pair[0]] * indiv_freq[pair[1]])\n",
    "    \n",
    "\n",
    "    return sorted(list(scores.items()),key=lambda item: item[1])\n",
    "\n",
    "\n",
    "# Time complexity : O(nb of letters in the text + n_pair*log(n_pair))\n",
    "            \n",
    "scores, indiv_freq = compute_init_scores(splits, word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(vocab: list, vocab_size: int, indiv_freq: defaultdict, word_freq: defaultdict, scores: list, splits: defaultdict) -> Tuple[list, defaultdict]:\n",
    "    while len(vocab) < vocab_size:\n",
    "        new_pair = scores[-1][0]\n",
    "        token_a = new_pair[0]\n",
    "        token_b = new_pair[1]\n",
    "        new_token = token_a + token_b[2:]\n",
    "        vocab.append(new_token) # remove '##' between tokens\n",
    "\n",
    "        # merge and update indiv_freq\n",
    "        for word,list_token in splits.items():\n",
    "            for i in range(len(list_token)-1):\n",
    "                if list_token[i] == token_a and list_token[i+1] == token_b:\n",
    "                    # pair found\n",
    "                    indiv_freq[token_a] -= word_freq[word]\n",
    "                    indiv_freq[token_b] -= word_freq[word]\n",
    "                    indiv_freq[new_token] += word_freq[word]\n",
    "                    split_left = []\n",
    "                    split_right = []\n",
    "                    if i > 0:\n",
    "                        split_left = splits[word][:i]\n",
    "                    if i < i-2:\n",
    "                        split_right = splits[word][i+2:]\n",
    "\n",
    "                    splits[word] = split_left + [new_token] + split_right\n",
    "        scores = compute_scores(splits, word_freq, indiv_freq)\n",
    "    return scores, splits\n",
    "\n",
    "\n",
    "scores, splits = iterate(vocab, 70, indiv_freq, word_freq, scores, splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
